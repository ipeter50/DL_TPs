{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq - Encoder/Decoder networks\n",
    "In this exercise we'll have a deeper look into the ability to use multiple RNN's to infer and generate sequences of data.\n",
    "Specifically we will implement a Encoder-Decoder RNN based for a simple sequence to sequence translation task.\n",
    "This type of models have shown impressive performance in Neural Machine Translation and Image Caption generation. \n",
    "\n",
    "In the encoder-decoder structure one RNN (blue) encodes the input into a hidden representation, and a second RNN (red) uses this representation to predict the target values.\n",
    "An essential step is deciding how the encoder and decoder should communicate.\n",
    "In the simplest approach you use the last hidden state of the encoder to initialize the decoder.\n",
    "This is what we will do in this notebook, as shown here:\n",
    "\n",
    "![](./images/enc-dec.png)\n",
    "\n",
    "In this exercise we will translate from the words of number (e.g. 'nine') to the actual number (e.g. '9').\n",
    "The input for the Encoder RNN consists of words defining the number, whilst the output of such an encoding serves as input for the Decoder RNN that aims to generate generate a number. \n",
    "Our dataset is generated and consists of numbers and an End-of-Sentence (EOS) character ('#'). The data we want to generate should be like follows:\n",
    "\n",
    "```\n",
    "Examples: \n",
    "prediction  |  input\n",
    "991136#00 \t nine nine one one three six\n",
    "81771#000 \t eight one seven seven one\n",
    "3519614#0 \t three five one nine six one four\n",
    "26656#000 \t two six six five six\n",
    "60344#000 \t six zero three four four\n",
    "162885#00 \t one six two eight eight five\n",
    "78612625# \t seven eight six one two six two five\n",
    "9464710#0 \t nine four six four seven one zero\n",
    "191306#00 \t one nine one three zero six\n",
    "10160378# \t one zero one zero six three seven eight\n",
    "```\n",
    "\n",
    "Let us define the space of characters and numbers to be learned with the networks:\n",
    "\n",
    "```\n",
    "Number of valid characters: 27\n",
    "'0'=0,\t'1'=1,\t'2'=2,\t'3'=3,\t'4'=4,\t'5'=5,\t'6'=6,\t'7'=7,\t'8'=8,\t'9'=9,\t'#'=10,\t' '=11,\t'e'=12,\t'g'=13,\t'f'=14,\t'i'=15,\t'h'=16,\t'o'=17,\t'n'=18,\t's'=19,\t'r'=20,\t'u'=21,\t't'=22,\t'w'=23,\t'v'=24,\t'x'=25,\t'z'=26,\t\n",
    "Stop/start character = #\n",
    "```\n",
    "\n",
    "All represented characters and numbers as characters, gets mapped to an integer from 0-26. Our total space of valid characters consists of 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n"
     ]
    }
   ],
   "source": [
    "from data_generator import generate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_generator import generate\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device in use:\", device)\n",
    "\n",
    "NUM_INPUTS = 27 #No. of possible characters\n",
    "NUM_OUTPUTS = 11  # (0-9 + '#')\n",
    "\n",
    "### Hyperparameters and general configs\n",
    "MAX_SEQ_LEN = 8\n",
    "MIN_SEQ_LEN = 5\n",
    "BATCH_SIZE = 80\n",
    "TRAINING_SIZE = 8000\n",
    "LEARNING_RATE = 0.003\n",
    "\n",
    "# Hidden size of enc and dec need to be equal if last hidden of encoder becomes init hidden of decoder\n",
    "# Otherwise we would need e.g. a linear layer to map to a space with the correct dimension\n",
    "NUM_UNITS_ENC = NUM_UNITS_DEC = 96\n",
    "TEST_SIZE = 200\n",
    "EPOCHS = 100\n",
    "TEACHER_FORCING = False\n",
    "\n",
    "assert TRAINING_SIZE % BATCH_SIZE == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we won´t worry about data generation, but utilise a built function for this purpose. The function generates random data constained by the 27 characters described above.\n",
    "\n",
    "The encoder takes as input the embedded text strings generated from the *generate* function as given here above ie. 'nine' would become [18 15 18 12].\n",
    "Sequeneces are generated at random given settings of minima and maxima length, constrained by the dimensions of the two RNN´s architecture.\n",
    "We may visualise a subset of the data generated by running the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch length 3 from 3 iterations\n",
      "input types: int32 int32 int32 int32 int32\n",
      "Number of valid characters: 27\n",
      "'0'=0,\t'1'=1,\t'2'=2,\t'3'=3,\t'4'=4,\t'5'=5,\t'6'=6,\t'7'=7,\t'8'=8,\t'9'=9,\t'#'=10,\t' '=11,\t'e'=12,\t'g'=13,\t'f'=14,\t'i'=15,\t'h'=16,\t'o'=17,\t'n'=18,\t's'=19,\t'r'=20,\t'u'=21,\t't'=22,\t'w'=23,\t'v'=24,\t'x'=25,\t'z'=26,\t\n",
      "Stop/start character = #\n",
      "\n",
      "SAMPLE 0\n",
      "TEXT INPUTS:\t\t\t three four eight two\n",
      "ENCODED INPUTS:\t\t\t [22 16 20 12 12 11 14 17 21 20 11 12 15 13 16 22 11 22 23 17]\n",
      "INPUTS SEQUENCE LENGTH:\t 20\n",
      "TEXT TARGETS INPUT:\t\t #3482\n",
      "TEXT TARGETS OUTPUT:\t 3482#\n",
      "ENCODED TARGETS INPUT:\t [10  3  4  8  2]\n",
      "ENCODED TARGETS OUTPUT:\t [ 3  4  8  2 10]\n",
      "TARGETS SEQUENCE LENGTH: 5\n",
      "TARGETS MASK:\t\t\t [ 1.  1.  1.  1.  1.]\n",
      "\n",
      "SAMPLE 1\n",
      "TEXT INPUTS:\t\t\t four eight\n",
      "ENCODED INPUTS:\t\t\t [14 17 21 20 11 12 15 13 16 22  0  0  0  0  0  0  0  0  0  0]\n",
      "INPUTS SEQUENCE LENGTH:\t 10\n",
      "TEXT TARGETS INPUT:\t\t #48\n",
      "TEXT TARGETS OUTPUT:\t 48#\n",
      "ENCODED TARGETS INPUT:\t [10  4  8  0  0]\n",
      "ENCODED TARGETS OUTPUT:\t [ 4  8 10  0  0]\n",
      "TARGETS SEQUENCE LENGTH: 3\n",
      "TARGETS MASK:\t\t\t [ 1.  1.  1.  0.  0.]\n",
      "\n",
      "SAMPLE 2\n",
      "TEXT INPUTS:\t\t\t five five seven\n",
      "ENCODED INPUTS:\t\t\t [14 15 24 12 11 14 15 24 12 11 19 12 24 12 18  0  0  0  0  0]\n",
      "INPUTS SEQUENCE LENGTH:\t 15\n",
      "TEXT TARGETS INPUT:\t\t #557\n",
      "TEXT TARGETS OUTPUT:\t 557#\n",
      "ENCODED TARGETS INPUT:\t [10  5  5  7  0]\n",
      "ENCODED TARGETS OUTPUT:\t [ 5  5  7 10  0]\n",
      "TARGETS SEQUENCE LENGTH: 4\n",
      "TARGETS MASK:\t\t\t [ 1.  1.  1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "!python ./data_generator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define the two RNN's\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, self.hidden_size)\n",
    "        rnn = nn.LSTM\n",
    "        self.rnn = rnn(self.hidden_size, self.hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        # Input shape [batch, seq_in_len]\n",
    "        inputs = inputs.long()\n",
    "\n",
    "        # Embedded shape [batch, seq_in_len, embed]\n",
    "        embedded = self.embedding(inputs)\n",
    "        \n",
    "        # Output shape [batch, seq_in_len, embed]\n",
    "        # Hidden shape [1, batch, embed], last hidden state of the GRU cell\n",
    "        # We will feed this last hidden state into the decoder\n",
    "        #print(hidden.size())\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        init = torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "        return (init, init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        rnn = nn.LSTM\n",
    "        self.rnn = rnn(self.hidden_size, self.hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs, hidden, output_len, teacher_forcing=False):\n",
    "        # Input shape: [batch, output_len]\n",
    "        # Hidden shape: [seq_len=1, batch_size, hidden_dim] (the last hidden state of the encoder)\n",
    "    \n",
    "        if teacher_forcing:\n",
    "            dec_input = inputs\n",
    "            embed = self.embedding(dec_input)   # shape [batch, output_len, hidden_dim]\n",
    "            out, hidden = self.rnn(embed, hidden)\n",
    "            out = self.out(out)  # linear layer, out has now shape [batch, output_len, output_size]\n",
    "            output = F.log_softmax(out, -1)\n",
    "        else:\n",
    "            # Take the EOS character only, for the whole batch, and unsqueeze so shape is [batch, 1]\n",
    "            # This is the first input, then we will use as input the GRU output at the previous time step\n",
    "            \n",
    "            dec_input = inputs[:, 0].unsqueeze(1)\n",
    "\n",
    "            output = []\n",
    "            for i in range(output_len):\n",
    "                out, hidden = self.rnn(self.embedding(dec_input), hidden)\n",
    "                out = self.out(out)  # linear layer, out has now shape [batch, 1, output_size]\n",
    "                out = F.log_softmax(out, -1)\n",
    "                output.append(out.squeeze(1))\n",
    "                out_symbol = torch.argmax(out, dim=2)   # shape [batch, 1]\n",
    "                dec_input = out_symbol   # feed the decoded symbol back into the recurrent unit at next step\n",
    "\n",
    "            output = torch.stack(output).permute(1, 0, 2)  # [batch_size x seq_len x output_size]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned representation from the *Encoder* gets propagated to the *Decoder* as the final hidden layer in the *Encoder* network is set as initialisation for the *Decoder*'s first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(encoder, decoder, x, t, t_in, criterion, max_t_len, teacher_forcing):\n",
    "    \"\"\"\n",
    "    Executes a forward pass through the whole model.\n",
    "\n",
    "    :param encoder:\n",
    "    :param decoder:\n",
    "    :param x: input to the encoder, shape [batch, seq_in_len]\n",
    "    :param t: target output predictions for decoder, shape [batch, seq_t_len]\n",
    "    :param criterion: loss function\n",
    "    :param max_t_len: maximum target length\n",
    "\n",
    "    :return: output (after log-softmax), loss, accuracy (per-symbol)\n",
    "    \"\"\"\n",
    "    # Run encoder and get last hidden state (and output)\n",
    "    batch_size = x.size(0)\n",
    "\n",
    "    enc_h = encoder.init_hidden(batch_size)\n",
    "    enc_out, enc_h = encoder(x, enc_h)\n",
    "\n",
    "    dec_h = enc_h  # Init hidden state of decoder as hidden state of encoder\n",
    "    dec_input = t_in\n",
    "    \n",
    "    out = decoder(dec_input, dec_h, max_t_len, True)\n",
    "    out = out.permute(0, 2, 1)\n",
    "    # Shape: [batch_size x num_classes x out_sequence_len], with second dim containing log probabilities\n",
    "\n",
    "    loss = criterion(out, t)\n",
    "    pred = get_pred(log_probs=out)\n",
    "\n",
    "    accuracy = (pred == t).type(torch.FloatTensor).mean()\n",
    "\n",
    "    return out, loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, inputs, targets, targets_in, criterion, enc_optimizer, dec_optimizer, epoch, max_t_len):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    for batch_idx, (x, t, t_in) in enumerate(zip(inputs, targets, targets_in)):\n",
    "        \n",
    "        \n",
    "        # getting the data on the device\n",
    "        x = x.to(device)\n",
    "        t = t.long().to(device)\n",
    "        t_in = t_in.long().to(device)\n",
    "        \n",
    "        # compute the networks outputs with doing a forward pass\n",
    "        # the forward pass calls succesively the encoder and the decoder and retrieves the output of the decoder\n",
    "        out, loss, accuracy = forward_pass(encoder, decoder, x, t, t_in, criterion, max_t_len,teacher_forcing=TEACHER_FORCING)\n",
    "        \n",
    "        # zero the gradient of optimizers\n",
    "        enc_optimizer.zero_grad()\n",
    "        dec_optimizer.zero_grad()\n",
    "        \n",
    "        # compute new gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # finally update network\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "        \n",
    "        \n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Epoch {} [{}/{} ({:.0f}%)]\\tTraining loss: {:.4f} \\tTraining accuracy: {:.1f}%'.format(\n",
    "                epoch, batch_idx * len(x), TRAINING_SIZE,\n",
    "                100. * batch_idx * len(x) / TRAINING_SIZE, loss.item(),\n",
    "                100. * accuracy.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder, decoder, inputs, targets, targets_in, criterion, max_t_len):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.long().to(device)\n",
    "        targets_in = targets_in.long().to(device)\n",
    "        out, loss, accuracy = forward_pass(encoder, decoder, inputs, targets, targets_in, criterion, max_t_len,\n",
    "                                           teacher_forcing=TEACHER_FORCING)\n",
    "    return out, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_to_text(seq):\n",
    "    return \"\".join([str(to_np(i)) if to_np(i) != 10 else '#' for i in seq])\n",
    "\n",
    "def to_np(x):\n",
    "    return x.cpu().numpy()\n",
    "\n",
    "def get_pred(log_probs):\n",
    "    \"\"\"\n",
    "    Get class prediction (digit prediction) from the net's output (the log_probs)\n",
    "    :param log_probs: Tensor of shape [batch_size x n_classes x sequence_len]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return torch.argmax(log_probs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch length 8000 from 8000 iterations\n",
      "Generated batch length 200 from 200 iterations\n",
      "Epoch 1 [0/8000 (0%)]\tTraining loss: 2.3956 \tTraining accuracy: 8.9%\n",
      "Epoch 1 [1600/8000 (20%)]\tTraining loss: 1.9403 \tTraining accuracy: 31.5%\n",
      "Epoch 1 [3200/8000 (40%)]\tTraining loss: 1.8578 \tTraining accuracy: 33.9%\n",
      "Epoch 1 [4800/8000 (60%)]\tTraining loss: 1.8112 \tTraining accuracy: 35.4%\n",
      "Epoch 1 [6400/8000 (80%)]\tTraining loss: 1.8024 \tTraining accuracy: 33.9%\n",
      "\n",
      "Test set: Average loss: 1.7846 \tAccuracy: 35.833%\n",
      "\n",
      "Examples: prediction | input\n",
      "0878377#0 \t four seven four zero six eight nine\n",
      "330706#00 \t six three one four nine eight\n",
      "22222#000 \t five nine two seven six\n",
      "313046000 \t zero nine one zero nine zero\n",
      "313011#00 \t zero two three zero six three\n",
      "22266#000 \t six one three one nine\n",
      "666620000 \t four three six eight zero\n",
      "222202#00 \t two nine two five five four\n",
      "22222##00 \t five five eight one two two\n",
      "222222##0 \t six one nine five two six six\n",
      "\n",
      "Epoch 2 [0/8000 (0%)]\tTraining loss: 1.7444 \tTraining accuracy: 34.2%\n",
      "Epoch 2 [1600/8000 (20%)]\tTraining loss: 1.7559 \tTraining accuracy: 35.0%\n",
      "Epoch 2 [3200/8000 (40%)]\tTraining loss: 1.7198 \tTraining accuracy: 37.6%\n",
      "Epoch 2 [4800/8000 (60%)]\tTraining loss: 1.6581 \tTraining accuracy: 37.2%\n",
      "Epoch 2 [6400/8000 (80%)]\tTraining loss: 1.7245 \tTraining accuracy: 37.4%\n",
      "\n",
      "Test set: Average loss: 1.6691 \tAccuracy: 39.000%\n",
      "\n",
      "Examples: prediction | input\n",
      "0069171#0 \t four seven four zero six eight nine\n",
      "337337#00 \t six three one four nine eight\n",
      "62290#000 \t five nine two seven six\n",
      "333337#00 \t zero nine one zero nine zero\n",
      "333333#00 \t zero two three zero six three\n",
      "33779#000 \t six one three one nine\n",
      "33337#000 \t four three six eight zero\n",
      "222000#00 \t two nine two five five four\n",
      "222222#00 \t five five eight one two two\n",
      "2222220#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 3 [0/8000 (0%)]\tTraining loss: 1.6283 \tTraining accuracy: 38.5%\n",
      "Epoch 3 [1600/8000 (20%)]\tTraining loss: 1.6193 \tTraining accuracy: 38.3%\n",
      "Epoch 3 [3200/8000 (40%)]\tTraining loss: 2.1778 \tTraining accuracy: 36.0%\n",
      "Epoch 3 [4800/8000 (60%)]\tTraining loss: 1.5352 \tTraining accuracy: 42.1%\n",
      "Epoch 3 [6400/8000 (80%)]\tTraining loss: 1.5716 \tTraining accuracy: 39.2%\n",
      "\n",
      "Test set: Average loss: 1.6284 \tAccuracy: 39.222%\n",
      "\n",
      "Examples: prediction | input\n",
      "0060004#0 \t four seven four zero six eight nine\n",
      "338557#00 \t six three one four nine eight\n",
      "22292#000 \t five nine two seven six\n",
      "612222#00 \t zero nine one zero nine zero\n",
      "333553#00 \t zero two three zero six three\n",
      "65566#000 \t six one three one nine\n",
      "33252#000 \t four three six eight zero\n",
      "222222#00 \t two nine two five five four\n",
      "222222#00 \t five five eight one two two\n",
      "2222222#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 4 [0/8000 (0%)]\tTraining loss: 1.5362 \tTraining accuracy: 41.0%\n",
      "Epoch 4 [1600/8000 (20%)]\tTraining loss: 1.5238 \tTraining accuracy: 42.8%\n",
      "Epoch 4 [3200/8000 (40%)]\tTraining loss: 1.4973 \tTraining accuracy: 45.0%\n",
      "Epoch 4 [4800/8000 (60%)]\tTraining loss: 1.4923 \tTraining accuracy: 41.1%\n",
      "Epoch 4 [6400/8000 (80%)]\tTraining loss: 1.5643 \tTraining accuracy: 41.1%\n",
      "\n",
      "Test set: Average loss: 1.5809 \tAccuracy: 40.444%\n",
      "\n",
      "Examples: prediction | input\n",
      "0660014#0 \t four seven four zero six eight nine\n",
      "331577#00 \t six three one four nine eight\n",
      "22292#000 \t five nine two seven six\n",
      "442226#00 \t zero nine one zero nine zero\n",
      "333153#00 \t zero two three zero six three\n",
      "63755#000 \t six one three one nine\n",
      "33575#000 \t four three six eight zero\n",
      "222266#00 \t two nine two five five four\n",
      "222222#00 \t five five eight one two two\n",
      "2222222#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 5 [0/8000 (0%)]\tTraining loss: 1.5166 \tTraining accuracy: 45.3%\n",
      "Epoch 5 [1600/8000 (20%)]\tTraining loss: 1.5087 \tTraining accuracy: 42.2%\n",
      "Epoch 5 [3200/8000 (40%)]\tTraining loss: 1.4794 \tTraining accuracy: 47.1%\n",
      "Epoch 5 [4800/8000 (60%)]\tTraining loss: 1.3891 \tTraining accuracy: 49.7%\n",
      "Epoch 5 [6400/8000 (80%)]\tTraining loss: 1.4354 \tTraining accuracy: 47.6%\n",
      "\n",
      "Test set: Average loss: 1.7412 \tAccuracy: 38.611%\n",
      "\n",
      "Examples: prediction | input\n",
      "44495747# \t four seven four zero six eight nine\n",
      "835583#00 \t six three one four nine eight\n",
      "22282#000 \t five nine two seven six\n",
      "444440#00 \t zero nine one zero nine zero\n",
      "333833#00 \t zero two three zero six three\n",
      "23355#000 \t six one three one nine\n",
      "33834#000 \t four three six eight zero\n",
      "211944#00 \t two nine two five five four\n",
      "822228#00 \t five five eight one two two\n",
      "2222222## \t six one nine five two six six\n",
      "\n",
      "Epoch 6 [0/8000 (0%)]\tTraining loss: 1.4509 \tTraining accuracy: 47.6%\n",
      "Epoch 6 [1600/8000 (20%)]\tTraining loss: 1.4083 \tTraining accuracy: 47.4%\n",
      "Epoch 6 [3200/8000 (40%)]\tTraining loss: 1.3149 \tTraining accuracy: 52.4%\n",
      "Epoch 6 [4800/8000 (60%)]\tTraining loss: 1.2397 \tTraining accuracy: 54.4%\n",
      "Epoch 6 [6400/8000 (80%)]\tTraining loss: 1.2269 \tTraining accuracy: 56.4%\n",
      "\n",
      "Test set: Average loss: 1.2216 \tAccuracy: 56.944%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440669#0 \t four seven four zero six eight nine\n",
      "214458#00 \t six three one four nine eight\n",
      "96272#000 \t five nine two seven six\n",
      "000090#00 \t zero nine one zero nine zero\n",
      "000063#00 \t zero two three zero six three\n",
      "61799#000 \t six one three one nine\n",
      "38684#000 \t four three six eight zero\n",
      "244444#00 \t two nine two five five four\n",
      "882222#00 \t five five eight one two two\n",
      "6662266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 7 [0/8000 (0%)]\tTraining loss: 1.1495 \tTraining accuracy: 60.0%\n",
      "Epoch 7 [1600/8000 (20%)]\tTraining loss: 1.1834 \tTraining accuracy: 56.4%\n",
      "Epoch 7 [3200/8000 (40%)]\tTraining loss: 1.1416 \tTraining accuracy: 59.0%\n",
      "Epoch 7 [4800/8000 (60%)]\tTraining loss: 1.0386 \tTraining accuracy: 62.5%\n",
      "Epoch 7 [6400/8000 (80%)]\tTraining loss: 1.0428 \tTraining accuracy: 63.2%\n",
      "\n",
      "Test set: Average loss: 1.0370 \tAccuracy: 63.278%\n",
      "\n",
      "Examples: prediction | input\n",
      "4446689#0 \t four seven four zero six eight nine\n",
      "610498#00 \t six three one four nine eight\n",
      "99696#000 \t five nine two seven six\n",
      "000000#00 \t zero nine one zero nine zero\n",
      "003033#00 \t zero two three zero six three\n",
      "61799#000 \t six one three one nine\n",
      "38880#000 \t four three six eight zero\n",
      "252544#00 \t two nine two five five four\n",
      "532222#00 \t five five eight one two two\n",
      "6966266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 8 [0/8000 (0%)]\tTraining loss: 0.9703 \tTraining accuracy: 67.9%\n",
      "Epoch 8 [1600/8000 (20%)]\tTraining loss: 0.9263 \tTraining accuracy: 66.1%\n",
      "Epoch 8 [3200/8000 (40%)]\tTraining loss: 0.9091 \tTraining accuracy: 68.5%\n",
      "Epoch 8 [4800/8000 (60%)]\tTraining loss: 0.8176 \tTraining accuracy: 69.4%\n",
      "Epoch 8 [6400/8000 (80%)]\tTraining loss: 0.7966 \tTraining accuracy: 72.8%\n",
      "\n",
      "Test set: Average loss: 0.8566 \tAccuracy: 71.222%\n",
      "\n",
      "Examples: prediction | input\n",
      "4444887#0 \t four seven four zero six eight nine\n",
      "631478#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023033#00 \t zero two three zero six three\n",
      "61719#000 \t six one three one nine\n",
      "33680#000 \t four three six eight zero\n",
      "255554#00 \t two nine two five five four\n",
      "538222#00 \t five five eight one two two\n",
      "6996666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 9 [0/8000 (0%)]\tTraining loss: 0.7415 \tTraining accuracy: 75.1%\n",
      "Epoch 9 [1600/8000 (20%)]\tTraining loss: 0.8593 \tTraining accuracy: 69.7%\n",
      "Epoch 9 [3200/8000 (40%)]\tTraining loss: 0.7302 \tTraining accuracy: 74.7%\n",
      "Epoch 9 [4800/8000 (60%)]\tTraining loss: 0.7013 \tTraining accuracy: 76.4%\n",
      "Epoch 9 [6400/8000 (80%)]\tTraining loss: 0.6816 \tTraining accuracy: 76.4%\n",
      "\n",
      "Test set: Average loss: 1.1362 \tAccuracy: 63.333%\n",
      "\n",
      "Examples: prediction | input\n",
      "444888##0 \t four seven four zero six eight nine\n",
      "630578#00 \t six three one four nine eight\n",
      "59771#000 \t five nine two seven six\n",
      "000000000 \t zero nine one zero nine zero\n",
      "023033#00 \t zero two three zero six three\n",
      "61711#000 \t six one three one nine\n",
      "338800000 \t four three six eight zero\n",
      "255544#00 \t two nine two five five four\n",
      "58822##00 \t five five eight one two two\n",
      "6992611#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 10 [0/8000 (0%)]\tTraining loss: 1.2636 \tTraining accuracy: 61.1%\n",
      "Epoch 10 [1600/8000 (20%)]\tTraining loss: 0.6266 \tTraining accuracy: 78.9%\n",
      "Epoch 10 [3200/8000 (40%)]\tTraining loss: 0.5948 \tTraining accuracy: 80.4%\n",
      "Epoch 10 [4800/8000 (60%)]\tTraining loss: 0.5651 \tTraining accuracy: 81.0%\n",
      "Epoch 10 [6400/8000 (80%)]\tTraining loss: 0.5978 \tTraining accuracy: 77.8%\n",
      "\n",
      "Test set: Average loss: 0.7224 \tAccuracy: 76.500%\n",
      "\n",
      "Examples: prediction | input\n",
      "4444885#0 \t four seven four zero six eight nine\n",
      "631488#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023663#00 \t zero two three zero six three\n",
      "61719#000 \t six one three one nine\n",
      "33680#000 \t four three six eight zero\n",
      "255554#00 \t two nine two five five four\n",
      "558222#00 \t five five eight one two two\n",
      "6996666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 11 [0/8000 (0%)]\tTraining loss: 0.5375 \tTraining accuracy: 82.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 [1600/8000 (20%)]\tTraining loss: 0.5058 \tTraining accuracy: 83.2%\n",
      "Epoch 11 [3200/8000 (40%)]\tTraining loss: 0.4816 \tTraining accuracy: 82.6%\n",
      "Epoch 11 [4800/8000 (60%)]\tTraining loss: 0.4342 \tTraining accuracy: 85.7%\n",
      "Epoch 11 [6400/8000 (80%)]\tTraining loss: 0.4833 \tTraining accuracy: 84.3%\n",
      "\n",
      "Test set: Average loss: 0.6109 \tAccuracy: 79.944%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023663#00 \t zero two three zero six three\n",
      "61719#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "255554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6996666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 12 [0/8000 (0%)]\tTraining loss: 0.4566 \tTraining accuracy: 85.1%\n",
      "Epoch 12 [1600/8000 (20%)]\tTraining loss: 0.4981 \tTraining accuracy: 84.2%\n",
      "Epoch 12 [3200/8000 (40%)]\tTraining loss: 0.4349 \tTraining accuracy: 85.6%\n",
      "Epoch 12 [4800/8000 (60%)]\tTraining loss: 0.3659 \tTraining accuracy: 87.8%\n",
      "Epoch 12 [6400/8000 (80%)]\tTraining loss: 0.4905 \tTraining accuracy: 83.9%\n",
      "\n",
      "Test set: Average loss: 0.5075 \tAccuracy: 83.722%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "090090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61199#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "255554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6995666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 13 [0/8000 (0%)]\tTraining loss: 0.3739 \tTraining accuracy: 87.9%\n",
      "Epoch 13 [1600/8000 (20%)]\tTraining loss: 0.3908 \tTraining accuracy: 85.7%\n",
      "Epoch 13 [3200/8000 (40%)]\tTraining loss: 0.3486 \tTraining accuracy: 87.2%\n",
      "Epoch 13 [4800/8000 (60%)]\tTraining loss: 0.3203 \tTraining accuracy: 89.4%\n",
      "Epoch 13 [6400/8000 (80%)]\tTraining loss: 0.3195 \tTraining accuracy: 89.7%\n",
      "\n",
      "Test set: Average loss: 0.4251 \tAccuracy: 86.000%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631418#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61119#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "255554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6995666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 14 [0/8000 (0%)]\tTraining loss: 0.3218 \tTraining accuracy: 91.3%\n",
      "Epoch 14 [1600/8000 (20%)]\tTraining loss: 0.3025 \tTraining accuracy: 89.6%\n",
      "Epoch 14 [3200/8000 (40%)]\tTraining loss: 0.9739 \tTraining accuracy: 70.1%\n",
      "Epoch 14 [4800/8000 (60%)]\tTraining loss: 0.2835 \tTraining accuracy: 89.7%\n",
      "Epoch 14 [6400/8000 (80%)]\tTraining loss: 0.2929 \tTraining accuracy: 91.3%\n",
      "\n",
      "Test set: Average loss: 0.4250 \tAccuracy: 86.167%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631418#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6995666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 15 [0/8000 (0%)]\tTraining loss: 0.2770 \tTraining accuracy: 91.7%\n",
      "Epoch 15 [1600/8000 (20%)]\tTraining loss: 0.2536 \tTraining accuracy: 92.6%\n",
      "Epoch 15 [3200/8000 (40%)]\tTraining loss: 0.3375 \tTraining accuracy: 88.2%\n",
      "Epoch 15 [4800/8000 (60%)]\tTraining loss: 0.2741 \tTraining accuracy: 90.7%\n",
      "Epoch 15 [6400/8000 (80%)]\tTraining loss: 0.2709 \tTraining accuracy: 91.8%\n",
      "\n",
      "Test set: Average loss: 0.4036 \tAccuracy: 87.444%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631418#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6995666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 16 [0/8000 (0%)]\tTraining loss: 0.2211 \tTraining accuracy: 93.6%\n",
      "Epoch 16 [1600/8000 (20%)]\tTraining loss: 0.2200 \tTraining accuracy: 92.9%\n",
      "Epoch 16 [3200/8000 (40%)]\tTraining loss: 0.3223 \tTraining accuracy: 89.0%\n",
      "Epoch 16 [4800/8000 (60%)]\tTraining loss: 0.2114 \tTraining accuracy: 92.8%\n",
      "Epoch 16 [6400/8000 (80%)]\tTraining loss: 0.2785 \tTraining accuracy: 91.4%\n",
      "\n",
      "Test set: Average loss: 0.3501 \tAccuracy: 88.389%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631497#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558222#00 \t five five eight one two two\n",
      "6195666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 17 [0/8000 (0%)]\tTraining loss: 0.2208 \tTraining accuracy: 92.2%\n",
      "Epoch 17 [1600/8000 (20%)]\tTraining loss: 0.1890 \tTraining accuracy: 94.9%\n",
      "Epoch 17 [3200/8000 (40%)]\tTraining loss: 0.2606 \tTraining accuracy: 91.7%\n",
      "Epoch 17 [4800/8000 (60%)]\tTraining loss: 0.1953 \tTraining accuracy: 93.3%\n",
      "Epoch 17 [6400/8000 (80%)]\tTraining loss: 0.2441 \tTraining accuracy: 91.4%\n",
      "\n",
      "Test set: Average loss: 0.3310 \tAccuracy: 89.833%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558222#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 18 [0/8000 (0%)]\tTraining loss: 0.1671 \tTraining accuracy: 94.7%\n",
      "Epoch 18 [1600/8000 (20%)]\tTraining loss: 0.1928 \tTraining accuracy: 94.0%\n",
      "Epoch 18 [3200/8000 (40%)]\tTraining loss: 0.1829 \tTraining accuracy: 93.6%\n",
      "Epoch 18 [4800/8000 (60%)]\tTraining loss: 0.1499 \tTraining accuracy: 94.9%\n",
      "Epoch 18 [6400/8000 (80%)]\tTraining loss: 0.2064 \tTraining accuracy: 92.6%\n",
      "\n",
      "Test set: Average loss: 0.3729 \tAccuracy: 89.611%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440889#0 \t four seven four zero six eight nine\n",
      "631418#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 19 [0/8000 (0%)]\tTraining loss: 0.1778 \tTraining accuracy: 94.0%\n",
      "Epoch 19 [1600/8000 (20%)]\tTraining loss: 0.2803 \tTraining accuracy: 92.1%\n",
      "Epoch 19 [3200/8000 (40%)]\tTraining loss: 0.1953 \tTraining accuracy: 93.8%\n",
      "Epoch 19 [4800/8000 (60%)]\tTraining loss: 0.1430 \tTraining accuracy: 95.7%\n",
      "Epoch 19 [6400/8000 (80%)]\tTraining loss: 0.1948 \tTraining accuracy: 92.9%\n",
      "\n",
      "Test set: Average loss: 0.3147 \tAccuracy: 90.556%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740889#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 20 [0/8000 (0%)]\tTraining loss: 0.1171 \tTraining accuracy: 97.6%\n",
      "Epoch 20 [1600/8000 (20%)]\tTraining loss: 0.1409 \tTraining accuracy: 96.4%\n",
      "Epoch 20 [3200/8000 (40%)]\tTraining loss: 0.1962 \tTraining accuracy: 92.4%\n",
      "Epoch 20 [4800/8000 (60%)]\tTraining loss: 0.1053 \tTraining accuracy: 96.5%\n",
      "Epoch 20 [6400/8000 (80%)]\tTraining loss: 0.1691 \tTraining accuracy: 93.2%\n",
      "\n",
      "Test set: Average loss: 0.3562 \tAccuracy: 89.389%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740699#0 \t four seven four zero six eight nine\n",
      "631497#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558222400 \t five five eight one two two\n",
      "6195666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 21 [0/8000 (0%)]\tTraining loss: 0.1157 \tTraining accuracy: 96.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 [1600/8000 (20%)]\tTraining loss: 0.2162 \tTraining accuracy: 94.2%\n",
      "Epoch 21 [3200/8000 (40%)]\tTraining loss: 0.1222 \tTraining accuracy: 96.4%\n",
      "Epoch 21 [4800/8000 (60%)]\tTraining loss: 0.1272 \tTraining accuracy: 96.0%\n",
      "Epoch 21 [6400/8000 (80%)]\tTraining loss: 0.2271 \tTraining accuracy: 91.0%\n",
      "\n",
      "Test set: Average loss: 0.3183 \tAccuracy: 91.333%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558222400 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 22 [0/8000 (0%)]\tTraining loss: 0.1070 \tTraining accuracy: 96.5%\n",
      "Epoch 22 [1600/8000 (20%)]\tTraining loss: 0.1073 \tTraining accuracy: 96.5%\n",
      "Epoch 22 [3200/8000 (40%)]\tTraining loss: 0.1385 \tTraining accuracy: 94.9%\n",
      "Epoch 22 [4800/8000 (60%)]\tTraining loss: 0.2456 \tTraining accuracy: 91.0%\n",
      "Epoch 22 [6400/8000 (80%)]\tTraining loss: 0.1238 \tTraining accuracy: 95.6%\n",
      "\n",
      "Test set: Average loss: 0.3400 \tAccuracy: 89.444%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440889#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "011190#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195262#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 23 [0/8000 (0%)]\tTraining loss: 0.1771 \tTraining accuracy: 94.6%\n",
      "Epoch 23 [1600/8000 (20%)]\tTraining loss: 0.0834 \tTraining accuracy: 97.6%\n",
      "Epoch 23 [3200/8000 (40%)]\tTraining loss: 0.2001 \tTraining accuracy: 92.5%\n",
      "Epoch 23 [4800/8000 (60%)]\tTraining loss: 0.0827 \tTraining accuracy: 97.5%\n",
      "Epoch 23 [6400/8000 (80%)]\tTraining loss: 0.2343 \tTraining accuracy: 91.8%\n",
      "\n",
      "Test set: Average loss: 0.2799 \tAccuracy: 91.667%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558224#00 \t five five eight one two two\n",
      "6195666#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 24 [0/8000 (0%)]\tTraining loss: 0.1055 \tTraining accuracy: 96.7%\n",
      "Epoch 24 [1600/8000 (20%)]\tTraining loss: 0.0876 \tTraining accuracy: 97.9%\n",
      "Epoch 24 [3200/8000 (40%)]\tTraining loss: 0.1148 \tTraining accuracy: 96.1%\n",
      "Epoch 24 [4800/8000 (60%)]\tTraining loss: 0.0649 \tTraining accuracy: 98.3%\n",
      "Epoch 24 [6400/8000 (80%)]\tTraining loss: 0.2794 \tTraining accuracy: 91.3%\n",
      "\n",
      "Test set: Average loss: 0.2582 \tAccuracy: 92.722%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558222#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 25 [0/8000 (0%)]\tTraining loss: 0.0893 \tTraining accuracy: 97.9%\n",
      "Epoch 25 [1600/8000 (20%)]\tTraining loss: 0.0831 \tTraining accuracy: 97.4%\n",
      "Epoch 25 [3200/8000 (40%)]\tTraining loss: 0.0896 \tTraining accuracy: 97.2%\n",
      "Epoch 25 [4800/8000 (60%)]\tTraining loss: 0.0733 \tTraining accuracy: 97.8%\n",
      "Epoch 25 [6400/8000 (80%)]\tTraining loss: 0.0959 \tTraining accuracy: 96.9%\n",
      "\n",
      "Test set: Average loss: 0.2442 \tAccuracy: 92.833%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558124#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 26 [0/8000 (0%)]\tTraining loss: 0.0773 \tTraining accuracy: 97.9%\n",
      "Epoch 26 [1600/8000 (20%)]\tTraining loss: 0.0701 \tTraining accuracy: 98.3%\n",
      "Epoch 26 [3200/8000 (40%)]\tTraining loss: 0.1500 \tTraining accuracy: 95.7%\n",
      "Epoch 26 [4800/8000 (60%)]\tTraining loss: 0.0989 \tTraining accuracy: 96.9%\n",
      "Epoch 26 [6400/8000 (80%)]\tTraining loss: 0.0893 \tTraining accuracy: 97.1%\n",
      "\n",
      "Test set: Average loss: 0.2414 \tAccuracy: 92.722%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 27 [0/8000 (0%)]\tTraining loss: 0.0760 \tTraining accuracy: 97.9%\n",
      "Epoch 27 [1600/8000 (20%)]\tTraining loss: 0.0659 \tTraining accuracy: 98.3%\n",
      "Epoch 27 [3200/8000 (40%)]\tTraining loss: 0.1636 \tTraining accuracy: 94.2%\n",
      "Epoch 27 [4800/8000 (60%)]\tTraining loss: 0.0711 \tTraining accuracy: 98.5%\n",
      "Epoch 27 [6400/8000 (80%)]\tTraining loss: 0.0837 \tTraining accuracy: 97.6%\n",
      "\n",
      "Test set: Average loss: 0.2928 \tAccuracy: 90.667%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 28 [0/8000 (0%)]\tTraining loss: 0.1022 \tTraining accuracy: 96.8%\n",
      "Epoch 28 [1600/8000 (20%)]\tTraining loss: 0.0490 \tTraining accuracy: 98.9%\n",
      "Epoch 28 [3200/8000 (40%)]\tTraining loss: 0.0759 \tTraining accuracy: 97.4%\n",
      "Epoch 28 [4800/8000 (60%)]\tTraining loss: 0.1892 \tTraining accuracy: 93.9%\n",
      "Epoch 28 [6400/8000 (80%)]\tTraining loss: 0.0784 \tTraining accuracy: 97.9%\n",
      "\n",
      "Test set: Average loss: 0.2182 \tAccuracy: 93.722%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091190#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 29 [0/8000 (0%)]\tTraining loss: 0.0942 \tTraining accuracy: 96.9%\n",
      "Epoch 29 [1600/8000 (20%)]\tTraining loss: 0.0573 \tTraining accuracy: 98.3%\n",
      "Epoch 29 [3200/8000 (40%)]\tTraining loss: 0.0519 \tTraining accuracy: 98.9%\n",
      "Epoch 29 [4800/8000 (60%)]\tTraining loss: 0.0652 \tTraining accuracy: 97.9%\n",
      "Epoch 29 [6400/8000 (80%)]\tTraining loss: 0.0960 \tTraining accuracy: 96.5%\n",
      "\n",
      "Test set: Average loss: 0.1818 \tAccuracy: 94.778%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 30 [0/8000 (0%)]\tTraining loss: 0.0523 \tTraining accuracy: 98.1%\n",
      "Epoch 30 [1600/8000 (20%)]\tTraining loss: 0.0554 \tTraining accuracy: 98.3%\n",
      "Epoch 30 [3200/8000 (40%)]\tTraining loss: 0.1224 \tTraining accuracy: 96.1%\n",
      "Epoch 30 [4800/8000 (60%)]\tTraining loss: 0.0464 \tTraining accuracy: 98.5%\n",
      "Epoch 30 [6400/8000 (80%)]\tTraining loss: 0.0726 \tTraining accuracy: 97.8%\n",
      "\n",
      "Test set: Average loss: 0.2220 \tAccuracy: 93.444%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 31 [0/8000 (0%)]\tTraining loss: 0.0489 \tTraining accuracy: 98.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 [1600/8000 (20%)]\tTraining loss: 0.0549 \tTraining accuracy: 98.6%\n",
      "Epoch 31 [3200/8000 (40%)]\tTraining loss: 0.0827 \tTraining accuracy: 97.4%\n",
      "Epoch 31 [4800/8000 (60%)]\tTraining loss: 0.0434 \tTraining accuracy: 98.6%\n",
      "Epoch 31 [6400/8000 (80%)]\tTraining loss: 0.0475 \tTraining accuracy: 98.8%\n",
      "\n",
      "Test set: Average loss: 0.2124 \tAccuracy: 93.778%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122600 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 32 [0/8000 (0%)]\tTraining loss: 0.0398 \tTraining accuracy: 99.2%\n",
      "Epoch 32 [1600/8000 (20%)]\tTraining loss: 0.9840 \tTraining accuracy: 78.6%\n",
      "Epoch 32 [3200/8000 (40%)]\tTraining loss: 0.0507 \tTraining accuracy: 98.5%\n",
      "Epoch 32 [4800/8000 (60%)]\tTraining loss: 0.0389 \tTraining accuracy: 98.9%\n",
      "Epoch 32 [6400/8000 (80%)]\tTraining loss: 0.0449 \tTraining accuracy: 99.0%\n",
      "\n",
      "Test set: Average loss: 0.1877 \tAccuracy: 94.611%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 33 [0/8000 (0%)]\tTraining loss: 0.0457 \tTraining accuracy: 98.8%\n",
      "Epoch 33 [1600/8000 (20%)]\tTraining loss: 0.0533 \tTraining accuracy: 97.9%\n",
      "Epoch 33 [3200/8000 (40%)]\tTraining loss: 0.0473 \tTraining accuracy: 98.6%\n",
      "Epoch 33 [4800/8000 (60%)]\tTraining loss: 0.0396 \tTraining accuracy: 99.0%\n",
      "Epoch 33 [6400/8000 (80%)]\tTraining loss: 0.0511 \tTraining accuracy: 98.5%\n",
      "\n",
      "Test set: Average loss: 0.1998 \tAccuracy: 93.333%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091199#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558222#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 34 [0/8000 (0%)]\tTraining loss: 0.0535 \tTraining accuracy: 98.6%\n",
      "Epoch 34 [1600/8000 (20%)]\tTraining loss: 0.0345 \tTraining accuracy: 99.4%\n",
      "Epoch 34 [3200/8000 (40%)]\tTraining loss: 0.0526 \tTraining accuracy: 98.5%\n",
      "Epoch 34 [4800/8000 (60%)]\tTraining loss: 0.0331 \tTraining accuracy: 99.0%\n",
      "Epoch 34 [6400/8000 (80%)]\tTraining loss: 0.2961 \tTraining accuracy: 91.3%\n",
      "\n",
      "Test set: Average loss: 0.1891 \tAccuracy: 94.667%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 35 [0/8000 (0%)]\tTraining loss: 0.0537 \tTraining accuracy: 98.5%\n",
      "Epoch 35 [1600/8000 (20%)]\tTraining loss: 0.0304 \tTraining accuracy: 99.4%\n",
      "Epoch 35 [3200/8000 (40%)]\tTraining loss: 0.0266 \tTraining accuracy: 99.6%\n",
      "Epoch 35 [4800/8000 (60%)]\tTraining loss: 0.0518 \tTraining accuracy: 98.3%\n",
      "Epoch 35 [6400/8000 (80%)]\tTraining loss: 0.5935 \tTraining accuracy: 84.4%\n",
      "\n",
      "Test set: Average loss: 0.2298 \tAccuracy: 93.667%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 36 [0/8000 (0%)]\tTraining loss: 0.0671 \tTraining accuracy: 98.2%\n",
      "Epoch 36 [1600/8000 (20%)]\tTraining loss: 0.0265 \tTraining accuracy: 99.7%\n",
      "Epoch 36 [3200/8000 (40%)]\tTraining loss: 0.0239 \tTraining accuracy: 99.9%\n",
      "Epoch 36 [4800/8000 (60%)]\tTraining loss: 0.0292 \tTraining accuracy: 99.6%\n",
      "Epoch 36 [6400/8000 (80%)]\tTraining loss: 0.0303 \tTraining accuracy: 99.3%\n",
      "\n",
      "Test set: Average loss: 0.1851 \tAccuracy: 94.722%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091099#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 37 [0/8000 (0%)]\tTraining loss: 0.0334 \tTraining accuracy: 99.3%\n",
      "Epoch 37 [1600/8000 (20%)]\tTraining loss: 0.0983 \tTraining accuracy: 96.4%\n",
      "Epoch 37 [3200/8000 (40%)]\tTraining loss: 0.0237 \tTraining accuracy: 99.6%\n",
      "Epoch 37 [4800/8000 (60%)]\tTraining loss: 0.0275 \tTraining accuracy: 99.6%\n",
      "Epoch 37 [6400/8000 (80%)]\tTraining loss: 0.0238 \tTraining accuracy: 99.6%\n",
      "\n",
      "Test set: Average loss: 0.1813 \tAccuracy: 94.667%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091099#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 38 [0/8000 (0%)]\tTraining loss: 0.0235 \tTraining accuracy: 99.7%\n",
      "Epoch 38 [1600/8000 (20%)]\tTraining loss: 0.6543 \tTraining accuracy: 83.9%\n",
      "Epoch 38 [3200/8000 (40%)]\tTraining loss: 0.0359 \tTraining accuracy: 99.0%\n",
      "Epoch 38 [4800/8000 (60%)]\tTraining loss: 0.0407 \tTraining accuracy: 98.9%\n",
      "Epoch 38 [6400/8000 (80%)]\tTraining loss: 0.0257 \tTraining accuracy: 99.6%\n",
      "\n",
      "Test set: Average loss: 0.1957 \tAccuracy: 94.833%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091099#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 39 [0/8000 (0%)]\tTraining loss: 0.0221 \tTraining accuracy: 99.4%\n",
      "Epoch 39 [1600/8000 (20%)]\tTraining loss: 0.0211 \tTraining accuracy: 99.4%\n",
      "Epoch 39 [3200/8000 (40%)]\tTraining loss: 0.0800 \tTraining accuracy: 97.2%\n",
      "Epoch 39 [4800/8000 (60%)]\tTraining loss: 0.0256 \tTraining accuracy: 99.4%\n",
      "Epoch 39 [6400/8000 (80%)]\tTraining loss: 0.0292 \tTraining accuracy: 99.3%\n",
      "\n",
      "Test set: Average loss: 0.2506 \tAccuracy: 91.333%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090000 \t zero nine one zero nine zero\n",
      "023062#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "436800000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "552222600 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 40 [0/8000 (0%)]\tTraining loss: 0.1285 \tTraining accuracy: 95.3%\n",
      "Epoch 40 [1600/8000 (20%)]\tTraining loss: 0.0361 \tTraining accuracy: 98.8%\n",
      "Epoch 40 [3200/8000 (40%)]\tTraining loss: 0.0261 \tTraining accuracy: 99.7%\n",
      "Epoch 40 [4800/8000 (60%)]\tTraining loss: 0.0237 \tTraining accuracy: 99.9%\n",
      "Epoch 40 [6400/8000 (80%)]\tTraining loss: 0.0238 \tTraining accuracy: 99.6%\n",
      "\n",
      "Test set: Average loss: 0.2386 \tAccuracy: 93.556%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 41 [0/8000 (0%)]\tTraining loss: 0.0658 \tTraining accuracy: 97.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 [1600/8000 (20%)]\tTraining loss: 0.0172 \tTraining accuracy: 99.9%\n",
      "Epoch 41 [3200/8000 (40%)]\tTraining loss: 0.0161 \tTraining accuracy: 99.7%\n",
      "Epoch 41 [4800/8000 (60%)]\tTraining loss: 0.0278 \tTraining accuracy: 99.7%\n",
      "Epoch 41 [6400/8000 (80%)]\tTraining loss: 0.0404 \tTraining accuracy: 99.0%\n",
      "\n",
      "Test set: Average loss: 0.1817 \tAccuracy: 95.500%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091099#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 42 [0/8000 (0%)]\tTraining loss: 0.0226 \tTraining accuracy: 99.3%\n",
      "Epoch 42 [1600/8000 (20%)]\tTraining loss: 0.0236 \tTraining accuracy: 99.6%\n",
      "Epoch 42 [3200/8000 (40%)]\tTraining loss: 0.0445 \tTraining accuracy: 98.3%\n",
      "Epoch 42 [4800/8000 (60%)]\tTraining loss: 0.0441 \tTraining accuracy: 99.0%\n",
      "Epoch 42 [6400/8000 (80%)]\tTraining loss: 0.0302 \tTraining accuracy: 99.0%\n",
      "\n",
      "Test set: Average loss: 0.1846 \tAccuracy: 95.389%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 43 [0/8000 (0%)]\tTraining loss: 0.0308 \tTraining accuracy: 99.2%\n",
      "Epoch 43 [1600/8000 (20%)]\tTraining loss: 0.0212 \tTraining accuracy: 99.3%\n",
      "Epoch 43 [3200/8000 (40%)]\tTraining loss: 0.0247 \tTraining accuracy: 99.3%\n",
      "Epoch 43 [4800/8000 (60%)]\tTraining loss: 0.0216 \tTraining accuracy: 99.6%\n",
      "Epoch 43 [6400/8000 (80%)]\tTraining loss: 0.9553 \tTraining accuracy: 79.0%\n",
      "\n",
      "Test set: Average loss: 0.1787 \tAccuracy: 95.111%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 44 [0/8000 (0%)]\tTraining loss: 0.0293 \tTraining accuracy: 99.4%\n",
      "Epoch 44 [1600/8000 (20%)]\tTraining loss: 0.0186 \tTraining accuracy: 99.6%\n",
      "Epoch 44 [3200/8000 (40%)]\tTraining loss: 0.0187 \tTraining accuracy: 99.7%\n",
      "Epoch 44 [4800/8000 (60%)]\tTraining loss: 0.0146 \tTraining accuracy: 99.9%\n",
      "Epoch 44 [6400/8000 (80%)]\tTraining loss: 0.0246 \tTraining accuracy: 99.6%\n",
      "\n",
      "Test set: Average loss: 0.1909 \tAccuracy: 95.222%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 45 [0/8000 (0%)]\tTraining loss: 0.0141 \tTraining accuracy: 99.7%\n",
      "Epoch 45 [1600/8000 (20%)]\tTraining loss: 0.0117 \tTraining accuracy: 99.9%\n",
      "Epoch 45 [3200/8000 (40%)]\tTraining loss: 0.0109 \tTraining accuracy: 99.9%\n",
      "Epoch 45 [4800/8000 (60%)]\tTraining loss: 0.1447 \tTraining accuracy: 94.9%\n",
      "Epoch 45 [6400/8000 (80%)]\tTraining loss: 0.0330 \tTraining accuracy: 99.0%\n",
      "\n",
      "Test set: Average loss: 0.1823 \tAccuracy: 95.056%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 46 [0/8000 (0%)]\tTraining loss: 0.0228 \tTraining accuracy: 99.2%\n",
      "Epoch 46 [1600/8000 (20%)]\tTraining loss: 0.0133 \tTraining accuracy: 99.9%\n",
      "Epoch 46 [3200/8000 (40%)]\tTraining loss: 0.0188 \tTraining accuracy: 99.7%\n",
      "Epoch 46 [4800/8000 (60%)]\tTraining loss: 0.0160 \tTraining accuracy: 99.7%\n",
      "Epoch 46 [6400/8000 (80%)]\tTraining loss: 0.0155 \tTraining accuracy: 99.9%\n",
      "\n",
      "Test set: Average loss: 0.1794 \tAccuracy: 95.444%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091099#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 47 [0/8000 (0%)]\tTraining loss: 0.0093 \tTraining accuracy: 100.0%\n",
      "Epoch 47 [1600/8000 (20%)]\tTraining loss: 0.0088 \tTraining accuracy: 100.0%\n",
      "Epoch 47 [3200/8000 (40%)]\tTraining loss: 0.2107 \tTraining accuracy: 94.7%\n",
      "Epoch 47 [4800/8000 (60%)]\tTraining loss: 0.0416 \tTraining accuracy: 99.3%\n",
      "Epoch 47 [6400/8000 (80%)]\tTraining loss: 0.0261 \tTraining accuracy: 99.6%\n",
      "\n",
      "Test set: Average loss: 0.1707 \tAccuracy: 95.722%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 48 [0/8000 (0%)]\tTraining loss: 0.0171 \tTraining accuracy: 99.9%\n",
      "Epoch 48 [1600/8000 (20%)]\tTraining loss: 0.0140 \tTraining accuracy: 99.7%\n",
      "Epoch 48 [3200/8000 (40%)]\tTraining loss: 0.0172 \tTraining accuracy: 99.4%\n",
      "Epoch 48 [4800/8000 (60%)]\tTraining loss: 0.0119 \tTraining accuracy: 99.9%\n",
      "Epoch 48 [6400/8000 (80%)]\tTraining loss: 0.0136 \tTraining accuracy: 99.9%\n",
      "\n",
      "Test set: Average loss: 0.1675 \tAccuracy: 95.500%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 49 [0/8000 (0%)]\tTraining loss: 0.0131 \tTraining accuracy: 99.7%\n",
      "Epoch 49 [1600/8000 (20%)]\tTraining loss: 0.0090 \tTraining accuracy: 99.9%\n",
      "Epoch 49 [3200/8000 (40%)]\tTraining loss: 0.6165 \tTraining accuracy: 86.4%\n",
      "Epoch 49 [4800/8000 (60%)]\tTraining loss: 0.0291 \tTraining accuracy: 99.2%\n",
      "Epoch 49 [6400/8000 (80%)]\tTraining loss: 0.0228 \tTraining accuracy: 99.7%\n",
      "\n",
      "Test set: Average loss: 0.1669 \tAccuracy: 94.833%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091099#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 50 [0/8000 (0%)]\tTraining loss: 0.0159 \tTraining accuracy: 99.7%\n",
      "Epoch 50 [1600/8000 (20%)]\tTraining loss: 0.0154 \tTraining accuracy: 99.6%\n",
      "Epoch 50 [3200/8000 (40%)]\tTraining loss: 0.0129 \tTraining accuracy: 99.9%\n",
      "Epoch 50 [4800/8000 (60%)]\tTraining loss: 0.0142 \tTraining accuracy: 99.7%\n",
      "Epoch 50 [6400/8000 (80%)]\tTraining loss: 0.0304 \tTraining accuracy: 99.3%\n",
      "\n",
      "Test set: Average loss: 0.1699 \tAccuracy: 95.222%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 51 [0/8000 (0%)]\tTraining loss: 0.0082 \tTraining accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 [1600/8000 (20%)]\tTraining loss: 0.0082 \tTraining accuracy: 99.9%\n",
      "Epoch 51 [3200/8000 (40%)]\tTraining loss: 0.1062 \tTraining accuracy: 97.1%\n",
      "Epoch 51 [4800/8000 (60%)]\tTraining loss: 0.0591 \tTraining accuracy: 98.1%\n",
      "Epoch 51 [6400/8000 (80%)]\tTraining loss: 0.0281 \tTraining accuracy: 99.3%\n",
      "\n",
      "Test set: Average loss: 0.1718 \tAccuracy: 95.056%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091099#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 52 [0/8000 (0%)]\tTraining loss: 0.0138 \tTraining accuracy: 99.9%\n",
      "Epoch 52 [1600/8000 (20%)]\tTraining loss: 0.0129 \tTraining accuracy: 99.9%\n",
      "Epoch 52 [3200/8000 (40%)]\tTraining loss: 0.0126 \tTraining accuracy: 99.6%\n",
      "Epoch 52 [4800/8000 (60%)]\tTraining loss: 0.0127 \tTraining accuracy: 100.0%\n",
      "Epoch 52 [6400/8000 (80%)]\tTraining loss: 0.0105 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1692 \tAccuracy: 95.278%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091099#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 53 [0/8000 (0%)]\tTraining loss: 0.0077 \tTraining accuracy: 100.0%\n",
      "Epoch 53 [1600/8000 (20%)]\tTraining loss: 0.0075 \tTraining accuracy: 99.9%\n",
      "Epoch 53 [3200/8000 (40%)]\tTraining loss: 0.0079 \tTraining accuracy: 100.0%\n",
      "Epoch 53 [4800/8000 (60%)]\tTraining loss: 0.0104 \tTraining accuracy: 100.0%\n",
      "Epoch 53 [6400/8000 (80%)]\tTraining loss: 0.0580 \tTraining accuracy: 98.8%\n",
      "\n",
      "Test set: Average loss: 0.1601 \tAccuracy: 95.611%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 54 [0/8000 (0%)]\tTraining loss: 0.0203 \tTraining accuracy: 99.6%\n",
      "Epoch 54 [1600/8000 (20%)]\tTraining loss: 0.0181 \tTraining accuracy: 99.2%\n",
      "Epoch 54 [3200/8000 (40%)]\tTraining loss: 0.0114 \tTraining accuracy: 100.0%\n",
      "Epoch 54 [4800/8000 (60%)]\tTraining loss: 0.0097 \tTraining accuracy: 100.0%\n",
      "Epoch 54 [6400/8000 (80%)]\tTraining loss: 0.0120 \tTraining accuracy: 99.9%\n",
      "\n",
      "Test set: Average loss: 0.1627 \tAccuracy: 95.444%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 55 [0/8000 (0%)]\tTraining loss: 0.0064 \tTraining accuracy: 100.0%\n",
      "Epoch 55 [1600/8000 (20%)]\tTraining loss: 0.0067 \tTraining accuracy: 99.9%\n",
      "Epoch 55 [3200/8000 (40%)]\tTraining loss: 0.0058 \tTraining accuracy: 100.0%\n",
      "Epoch 55 [4800/8000 (60%)]\tTraining loss: 0.0052 \tTraining accuracy: 100.0%\n",
      "Epoch 55 [6400/8000 (80%)]\tTraining loss: 0.0065 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1490 \tAccuracy: 96.056%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 56 [0/8000 (0%)]\tTraining loss: 0.0066 \tTraining accuracy: 100.0%\n",
      "Epoch 56 [1600/8000 (20%)]\tTraining loss: 0.0459 \tTraining accuracy: 98.5%\n",
      "Epoch 56 [3200/8000 (40%)]\tTraining loss: 0.0184 \tTraining accuracy: 99.7%\n",
      "Epoch 56 [4800/8000 (60%)]\tTraining loss: 0.0171 \tTraining accuracy: 99.7%\n",
      "Epoch 56 [6400/8000 (80%)]\tTraining loss: 0.0180 \tTraining accuracy: 99.7%\n",
      "\n",
      "Test set: Average loss: 0.1429 \tAccuracy: 95.889%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 57 [0/8000 (0%)]\tTraining loss: 0.0161 \tTraining accuracy: 99.6%\n",
      "Epoch 57 [1600/8000 (20%)]\tTraining loss: 0.0131 \tTraining accuracy: 99.7%\n",
      "Epoch 57 [3200/8000 (40%)]\tTraining loss: 0.0116 \tTraining accuracy: 99.9%\n",
      "Epoch 57 [4800/8000 (60%)]\tTraining loss: 0.0086 \tTraining accuracy: 100.0%\n",
      "Epoch 57 [6400/8000 (80%)]\tTraining loss: 0.0077 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1709 \tAccuracy: 95.500%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 58 [0/8000 (0%)]\tTraining loss: 0.0079 \tTraining accuracy: 100.0%\n",
      "Epoch 58 [1600/8000 (20%)]\tTraining loss: 0.0106 \tTraining accuracy: 100.0%\n",
      "Epoch 58 [3200/8000 (40%)]\tTraining loss: 0.1033 \tTraining accuracy: 96.9%\n",
      "Epoch 58 [4800/8000 (60%)]\tTraining loss: 0.0183 \tTraining accuracy: 99.6%\n",
      "Epoch 58 [6400/8000 (80%)]\tTraining loss: 0.0152 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1670 \tAccuracy: 95.111%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 59 [0/8000 (0%)]\tTraining loss: 0.0169 \tTraining accuracy: 99.7%\n",
      "Epoch 59 [1600/8000 (20%)]\tTraining loss: 0.0104 \tTraining accuracy: 99.9%\n",
      "Epoch 59 [3200/8000 (40%)]\tTraining loss: 0.0107 \tTraining accuracy: 100.0%\n",
      "Epoch 59 [4800/8000 (60%)]\tTraining loss: 0.0054 \tTraining accuracy: 100.0%\n",
      "Epoch 59 [6400/8000 (80%)]\tTraining loss: 0.0064 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1605 \tAccuracy: 95.722%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 60 [0/8000 (0%)]\tTraining loss: 0.0057 \tTraining accuracy: 100.0%\n",
      "Epoch 60 [1600/8000 (20%)]\tTraining loss: 0.0064 \tTraining accuracy: 100.0%\n",
      "Epoch 60 [3200/8000 (40%)]\tTraining loss: 0.0106 \tTraining accuracy: 99.9%\n",
      "Epoch 60 [4800/8000 (60%)]\tTraining loss: 0.0198 \tTraining accuracy: 99.4%\n",
      "Epoch 60 [6400/8000 (80%)]\tTraining loss: 0.0342 \tTraining accuracy: 99.3%\n",
      "\n",
      "Test set: Average loss: 0.1975 \tAccuracy: 94.667%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554100 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 61 [0/8000 (0%)]\tTraining loss: 0.0187 \tTraining accuracy: 99.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 [1600/8000 (20%)]\tTraining loss: 0.0120 \tTraining accuracy: 99.7%\n",
      "Epoch 61 [3200/8000 (40%)]\tTraining loss: 0.0070 \tTraining accuracy: 100.0%\n",
      "Epoch 61 [4800/8000 (60%)]\tTraining loss: 0.0063 \tTraining accuracy: 100.0%\n",
      "Epoch 61 [6400/8000 (80%)]\tTraining loss: 0.0195 \tTraining accuracy: 99.2%\n",
      "\n",
      "Test set: Average loss: 0.1760 \tAccuracy: 95.333%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 62 [0/8000 (0%)]\tTraining loss: 0.0280 \tTraining accuracy: 98.9%\n",
      "Epoch 62 [1600/8000 (20%)]\tTraining loss: 0.5959 \tTraining accuracy: 83.3%\n",
      "Epoch 62 [3200/8000 (40%)]\tTraining loss: 0.0202 \tTraining accuracy: 99.6%\n",
      "Epoch 62 [4800/8000 (60%)]\tTraining loss: 0.0166 \tTraining accuracy: 99.7%\n",
      "Epoch 62 [6400/8000 (80%)]\tTraining loss: 0.0130 \tTraining accuracy: 99.7%\n",
      "\n",
      "Test set: Average loss: 0.1659 \tAccuracy: 95.611%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 63 [0/8000 (0%)]\tTraining loss: 0.0128 \tTraining accuracy: 99.7%\n",
      "Epoch 63 [1600/8000 (20%)]\tTraining loss: 0.0085 \tTraining accuracy: 99.9%\n",
      "Epoch 63 [3200/8000 (40%)]\tTraining loss: 0.0059 \tTraining accuracy: 100.0%\n",
      "Epoch 63 [4800/8000 (60%)]\tTraining loss: 0.0056 \tTraining accuracy: 100.0%\n",
      "Epoch 63 [6400/8000 (80%)]\tTraining loss: 0.0068 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1704 \tAccuracy: 95.333%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 64 [0/8000 (0%)]\tTraining loss: 0.0052 \tTraining accuracy: 100.0%\n",
      "Epoch 64 [1600/8000 (20%)]\tTraining loss: 0.0051 \tTraining accuracy: 100.0%\n",
      "Epoch 64 [3200/8000 (40%)]\tTraining loss: 0.0042 \tTraining accuracy: 100.0%\n",
      "Epoch 64 [4800/8000 (60%)]\tTraining loss: 0.0042 \tTraining accuracy: 100.0%\n",
      "Epoch 64 [6400/8000 (80%)]\tTraining loss: 0.0041 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1765 \tAccuracy: 95.444%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 65 [0/8000 (0%)]\tTraining loss: 0.0042 \tTraining accuracy: 100.0%\n",
      "Epoch 65 [1600/8000 (20%)]\tTraining loss: 0.0062 \tTraining accuracy: 100.0%\n",
      "Epoch 65 [3200/8000 (40%)]\tTraining loss: 0.0517 \tTraining accuracy: 97.9%\n",
      "Epoch 65 [4800/8000 (60%)]\tTraining loss: 0.0134 \tTraining accuracy: 99.9%\n",
      "Epoch 65 [6400/8000 (80%)]\tTraining loss: 0.0114 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.2035 \tAccuracy: 94.556%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091099#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 66 [0/8000 (0%)]\tTraining loss: 0.0180 \tTraining accuracy: 99.6%\n",
      "Epoch 66 [1600/8000 (20%)]\tTraining loss: 0.0076 \tTraining accuracy: 99.9%\n",
      "Epoch 66 [3200/8000 (40%)]\tTraining loss: 0.0048 \tTraining accuracy: 100.0%\n",
      "Epoch 66 [4800/8000 (60%)]\tTraining loss: 0.0086 \tTraining accuracy: 99.9%\n",
      "Epoch 66 [6400/8000 (80%)]\tTraining loss: 0.0074 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1665 \tAccuracy: 95.111%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 67 [0/8000 (0%)]\tTraining loss: 0.0052 \tTraining accuracy: 100.0%\n",
      "Epoch 67 [1600/8000 (20%)]\tTraining loss: 0.0040 \tTraining accuracy: 100.0%\n",
      "Epoch 67 [3200/8000 (40%)]\tTraining loss: 0.0039 \tTraining accuracy: 100.0%\n",
      "Epoch 67 [4800/8000 (60%)]\tTraining loss: 0.0029 \tTraining accuracy: 100.0%\n",
      "Epoch 67 [6400/8000 (80%)]\tTraining loss: 0.0035 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1681 \tAccuracy: 95.667%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 68 [0/8000 (0%)]\tTraining loss: 0.0029 \tTraining accuracy: 100.0%\n",
      "Epoch 68 [1600/8000 (20%)]\tTraining loss: 0.0024 \tTraining accuracy: 100.0%\n",
      "Epoch 68 [3200/8000 (40%)]\tTraining loss: 0.0366 \tTraining accuracy: 99.0%\n",
      "Epoch 68 [4800/8000 (60%)]\tTraining loss: 0.0178 \tTraining accuracy: 99.7%\n",
      "Epoch 68 [6400/8000 (80%)]\tTraining loss: 0.0164 \tTraining accuracy: 99.7%\n",
      "\n",
      "Test set: Average loss: 0.1874 \tAccuracy: 94.722%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195262#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 69 [0/8000 (0%)]\tTraining loss: 0.0130 \tTraining accuracy: 99.7%\n",
      "Epoch 69 [1600/8000 (20%)]\tTraining loss: 0.0061 \tTraining accuracy: 100.0%\n",
      "Epoch 69 [3200/8000 (40%)]\tTraining loss: 0.0081 \tTraining accuracy: 99.9%\n",
      "Epoch 69 [4800/8000 (60%)]\tTraining loss: 0.0044 \tTraining accuracy: 100.0%\n",
      "Epoch 69 [6400/8000 (80%)]\tTraining loss: 0.0064 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1882 \tAccuracy: 95.167%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195262#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 70 [0/8000 (0%)]\tTraining loss: 0.0057 \tTraining accuracy: 100.0%\n",
      "Epoch 70 [1600/8000 (20%)]\tTraining loss: 0.0063 \tTraining accuracy: 100.0%\n",
      "Epoch 70 [3200/8000 (40%)]\tTraining loss: 0.0038 \tTraining accuracy: 100.0%\n",
      "Epoch 70 [4800/8000 (60%)]\tTraining loss: 0.0024 \tTraining accuracy: 100.0%\n",
      "Epoch 70 [6400/8000 (80%)]\tTraining loss: 0.0051 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1874 \tAccuracy: 94.944%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 71 [0/8000 (0%)]\tTraining loss: 0.0031 \tTraining accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 [1600/8000 (20%)]\tTraining loss: 0.0025 \tTraining accuracy: 100.0%\n",
      "Epoch 71 [3200/8000 (40%)]\tTraining loss: 0.0029 \tTraining accuracy: 100.0%\n",
      "Epoch 71 [4800/8000 (60%)]\tTraining loss: 0.0027 \tTraining accuracy: 100.0%\n",
      "Epoch 71 [6400/8000 (80%)]\tTraining loss: 0.1453 \tTraining accuracy: 95.0%\n",
      "\n",
      "Test set: Average loss: 0.2397 \tAccuracy: 93.944%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122200 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 72 [0/8000 (0%)]\tTraining loss: 0.0416 \tTraining accuracy: 98.8%\n",
      "Epoch 72 [1600/8000 (20%)]\tTraining loss: 0.0169 \tTraining accuracy: 99.6%\n",
      "Epoch 72 [3200/8000 (40%)]\tTraining loss: 0.0142 \tTraining accuracy: 99.7%\n",
      "Epoch 72 [4800/8000 (60%)]\tTraining loss: 0.0085 \tTraining accuracy: 100.0%\n",
      "Epoch 72 [6400/8000 (80%)]\tTraining loss: 0.0077 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1664 \tAccuracy: 95.556%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 73 [0/8000 (0%)]\tTraining loss: 0.0090 \tTraining accuracy: 99.9%\n",
      "Epoch 73 [1600/8000 (20%)]\tTraining loss: 0.0052 \tTraining accuracy: 100.0%\n",
      "Epoch 73 [3200/8000 (40%)]\tTraining loss: 0.0041 \tTraining accuracy: 100.0%\n",
      "Epoch 73 [4800/8000 (60%)]\tTraining loss: 0.0029 \tTraining accuracy: 100.0%\n",
      "Epoch 73 [6400/8000 (80%)]\tTraining loss: 0.0037 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1722 \tAccuracy: 95.444%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 74 [0/8000 (0%)]\tTraining loss: 0.0040 \tTraining accuracy: 100.0%\n",
      "Epoch 74 [1600/8000 (20%)]\tTraining loss: 0.0033 \tTraining accuracy: 100.0%\n",
      "Epoch 74 [3200/8000 (40%)]\tTraining loss: 0.0034 \tTraining accuracy: 100.0%\n",
      "Epoch 74 [4800/8000 (60%)]\tTraining loss: 0.0021 \tTraining accuracy: 100.0%\n",
      "Epoch 74 [6400/8000 (80%)]\tTraining loss: 0.1572 \tTraining accuracy: 94.9%\n",
      "\n",
      "Test set: Average loss: 0.1796 \tAccuracy: 95.056%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 75 [0/8000 (0%)]\tTraining loss: 0.0285 \tTraining accuracy: 99.0%\n",
      "Epoch 75 [1600/8000 (20%)]\tTraining loss: 0.0097 \tTraining accuracy: 99.9%\n",
      "Epoch 75 [3200/8000 (40%)]\tTraining loss: 0.0095 \tTraining accuracy: 99.9%\n",
      "Epoch 75 [4800/8000 (60%)]\tTraining loss: 0.0074 \tTraining accuracy: 100.0%\n",
      "Epoch 75 [6400/8000 (80%)]\tTraining loss: 0.0066 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1871 \tAccuracy: 95.278%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 76 [0/8000 (0%)]\tTraining loss: 0.0047 \tTraining accuracy: 100.0%\n",
      "Epoch 76 [1600/8000 (20%)]\tTraining loss: 0.0049 \tTraining accuracy: 100.0%\n",
      "Epoch 76 [3200/8000 (40%)]\tTraining loss: 0.0033 \tTraining accuracy: 100.0%\n",
      "Epoch 76 [4800/8000 (60%)]\tTraining loss: 0.0026 \tTraining accuracy: 100.0%\n",
      "Epoch 76 [6400/8000 (80%)]\tTraining loss: 0.0033 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1767 \tAccuracy: 95.444%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 77 [0/8000 (0%)]\tTraining loss: 0.0026 \tTraining accuracy: 100.0%\n",
      "Epoch 77 [1600/8000 (20%)]\tTraining loss: 0.0024 \tTraining accuracy: 100.0%\n",
      "Epoch 77 [3200/8000 (40%)]\tTraining loss: 0.0021 \tTraining accuracy: 100.0%\n",
      "Epoch 77 [4800/8000 (60%)]\tTraining loss: 0.0018 \tTraining accuracy: 100.0%\n",
      "Epoch 77 [6400/8000 (80%)]\tTraining loss: 0.0022 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1800 \tAccuracy: 95.500%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 78 [0/8000 (0%)]\tTraining loss: 0.0018 \tTraining accuracy: 100.0%\n",
      "Epoch 78 [1600/8000 (20%)]\tTraining loss: 0.0017 \tTraining accuracy: 100.0%\n",
      "Epoch 78 [3200/8000 (40%)]\tTraining loss: 0.0017 \tTraining accuracy: 100.0%\n",
      "Epoch 78 [4800/8000 (60%)]\tTraining loss: 0.0014 \tTraining accuracy: 100.0%\n",
      "Epoch 78 [6400/8000 (80%)]\tTraining loss: 0.0018 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1813 \tAccuracy: 95.667%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 79 [0/8000 (0%)]\tTraining loss: 0.0013 \tTraining accuracy: 100.0%\n",
      "Epoch 79 [1600/8000 (20%)]\tTraining loss: 0.0571 \tTraining accuracy: 98.5%\n",
      "Epoch 79 [3200/8000 (40%)]\tTraining loss: 0.0285 \tTraining accuracy: 99.0%\n",
      "Epoch 79 [4800/8000 (60%)]\tTraining loss: 0.0185 \tTraining accuracy: 99.7%\n",
      "Epoch 79 [6400/8000 (80%)]\tTraining loss: 0.0128 \tTraining accuracy: 99.7%\n",
      "\n",
      "Test set: Average loss: 0.1612 \tAccuracy: 95.611%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 80 [0/8000 (0%)]\tTraining loss: 0.0114 \tTraining accuracy: 99.7%\n",
      "Epoch 80 [1600/8000 (20%)]\tTraining loss: 0.0098 \tTraining accuracy: 99.7%\n",
      "Epoch 80 [3200/8000 (40%)]\tTraining loss: 0.0077 \tTraining accuracy: 99.9%\n",
      "Epoch 80 [4800/8000 (60%)]\tTraining loss: 0.0060 \tTraining accuracy: 99.9%\n",
      "Epoch 80 [6400/8000 (80%)]\tTraining loss: 0.0045 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1709 \tAccuracy: 95.833%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 81 [0/8000 (0%)]\tTraining loss: 0.0046 \tTraining accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 [1600/8000 (20%)]\tTraining loss: 0.0037 \tTraining accuracy: 100.0%\n",
      "Epoch 81 [3200/8000 (40%)]\tTraining loss: 0.0026 \tTraining accuracy: 100.0%\n",
      "Epoch 81 [4800/8000 (60%)]\tTraining loss: 0.0021 \tTraining accuracy: 100.0%\n",
      "Epoch 81 [6400/8000 (80%)]\tTraining loss: 0.0026 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1681 \tAccuracy: 95.833%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 82 [0/8000 (0%)]\tTraining loss: 0.0023 \tTraining accuracy: 100.0%\n",
      "Epoch 82 [1600/8000 (20%)]\tTraining loss: 0.0021 \tTraining accuracy: 100.0%\n",
      "Epoch 82 [3200/8000 (40%)]\tTraining loss: 0.0027 \tTraining accuracy: 100.0%\n",
      "Epoch 82 [4800/8000 (60%)]\tTraining loss: 0.0398 \tTraining accuracy: 98.6%\n",
      "Epoch 82 [6400/8000 (80%)]\tTraining loss: 0.0251 \tTraining accuracy: 99.0%\n",
      "\n",
      "Test set: Average loss: 0.1631 \tAccuracy: 95.722%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 83 [0/8000 (0%)]\tTraining loss: 0.0136 \tTraining accuracy: 99.6%\n",
      "Epoch 83 [1600/8000 (20%)]\tTraining loss: 0.0097 \tTraining accuracy: 100.0%\n",
      "Epoch 83 [3200/8000 (40%)]\tTraining loss: 0.0071 \tTraining accuracy: 100.0%\n",
      "Epoch 83 [4800/8000 (60%)]\tTraining loss: 0.0043 \tTraining accuracy: 100.0%\n",
      "Epoch 83 [6400/8000 (80%)]\tTraining loss: 0.0051 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1548 \tAccuracy: 95.833%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 84 [0/8000 (0%)]\tTraining loss: 0.0035 \tTraining accuracy: 100.0%\n",
      "Epoch 84 [1600/8000 (20%)]\tTraining loss: 0.0041 \tTraining accuracy: 100.0%\n",
      "Epoch 84 [3200/8000 (40%)]\tTraining loss: 0.0045 \tTraining accuracy: 100.0%\n",
      "Epoch 84 [4800/8000 (60%)]\tTraining loss: 0.0025 \tTraining accuracy: 100.0%\n",
      "Epoch 84 [6400/8000 (80%)]\tTraining loss: 0.0030 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1498 \tAccuracy: 95.778%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 85 [0/8000 (0%)]\tTraining loss: 0.0027 \tTraining accuracy: 100.0%\n",
      "Epoch 85 [1600/8000 (20%)]\tTraining loss: 0.0021 \tTraining accuracy: 100.0%\n",
      "Epoch 85 [3200/8000 (40%)]\tTraining loss: 0.0029 \tTraining accuracy: 100.0%\n",
      "Epoch 85 [4800/8000 (60%)]\tTraining loss: 0.0319 \tTraining accuracy: 99.2%\n",
      "Epoch 85 [6400/8000 (80%)]\tTraining loss: 0.0150 \tTraining accuracy: 99.6%\n",
      "\n",
      "Test set: Average loss: 0.1966 \tAccuracy: 94.667%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195262#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 86 [0/8000 (0%)]\tTraining loss: 0.0232 \tTraining accuracy: 99.3%\n",
      "Epoch 86 [1600/8000 (20%)]\tTraining loss: 0.0112 \tTraining accuracy: 99.7%\n",
      "Epoch 86 [3200/8000 (40%)]\tTraining loss: 0.0055 \tTraining accuracy: 100.0%\n",
      "Epoch 86 [4800/8000 (60%)]\tTraining loss: 0.0052 \tTraining accuracy: 100.0%\n",
      "Epoch 86 [6400/8000 (80%)]\tTraining loss: 0.0072 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1631 \tAccuracy: 95.444%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195262#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 87 [0/8000 (0%)]\tTraining loss: 0.0038 \tTraining accuracy: 99.9%\n",
      "Epoch 87 [1600/8000 (20%)]\tTraining loss: 0.0037 \tTraining accuracy: 100.0%\n",
      "Epoch 87 [3200/8000 (40%)]\tTraining loss: 0.0067 \tTraining accuracy: 99.9%\n",
      "Epoch 87 [4800/8000 (60%)]\tTraining loss: 0.0023 \tTraining accuracy: 100.0%\n",
      "Epoch 87 [6400/8000 (80%)]\tTraining loss: 0.0024 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1600 \tAccuracy: 96.000%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 88 [0/8000 (0%)]\tTraining loss: 0.0021 \tTraining accuracy: 100.0%\n",
      "Epoch 88 [1600/8000 (20%)]\tTraining loss: 0.0022 \tTraining accuracy: 100.0%\n",
      "Epoch 88 [3200/8000 (40%)]\tTraining loss: 0.0022 \tTraining accuracy: 100.0%\n",
      "Epoch 88 [4800/8000 (60%)]\tTraining loss: 0.0013 \tTraining accuracy: 100.0%\n",
      "Epoch 88 [6400/8000 (80%)]\tTraining loss: 0.0020 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1632 \tAccuracy: 96.167%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 89 [0/8000 (0%)]\tTraining loss: 0.0015 \tTraining accuracy: 100.0%\n",
      "Epoch 89 [1600/8000 (20%)]\tTraining loss: 0.0015 \tTraining accuracy: 100.0%\n",
      "Epoch 89 [3200/8000 (40%)]\tTraining loss: 0.0014 \tTraining accuracy: 100.0%\n",
      "Epoch 89 [4800/8000 (60%)]\tTraining loss: 0.0011 \tTraining accuracy: 100.0%\n",
      "Epoch 89 [6400/8000 (80%)]\tTraining loss: 0.0012 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1586 \tAccuracy: 96.278%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 90 [0/8000 (0%)]\tTraining loss: 0.0011 \tTraining accuracy: 100.0%\n",
      "Epoch 90 [1600/8000 (20%)]\tTraining loss: 0.0011 \tTraining accuracy: 100.0%\n",
      "Epoch 90 [3200/8000 (40%)]\tTraining loss: 0.0013 \tTraining accuracy: 100.0%\n",
      "Epoch 90 [4800/8000 (60%)]\tTraining loss: 0.0008 \tTraining accuracy: 100.0%\n",
      "Epoch 90 [6400/8000 (80%)]\tTraining loss: 0.0913 \tTraining accuracy: 97.4%\n",
      "\n",
      "Test set: Average loss: 0.1522 \tAccuracy: 95.944%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023068#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195262#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 91 [0/8000 (0%)]\tTraining loss: 0.0288 \tTraining accuracy: 98.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 [1600/8000 (20%)]\tTraining loss: 0.0261 \tTraining accuracy: 99.2%\n",
      "Epoch 91 [3200/8000 (40%)]\tTraining loss: 0.0142 \tTraining accuracy: 99.9%\n",
      "Epoch 91 [4800/8000 (60%)]\tTraining loss: 0.0087 \tTraining accuracy: 100.0%\n",
      "Epoch 91 [6400/8000 (80%)]\tTraining loss: 0.0066 \tTraining accuracy: 99.9%\n",
      "\n",
      "Test set: Average loss: 0.1491 \tAccuracy: 95.944%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195262#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 92 [0/8000 (0%)]\tTraining loss: 0.0050 \tTraining accuracy: 100.0%\n",
      "Epoch 92 [1600/8000 (20%)]\tTraining loss: 0.0031 \tTraining accuracy: 100.0%\n",
      "Epoch 92 [3200/8000 (40%)]\tTraining loss: 0.0100 \tTraining accuracy: 99.6%\n",
      "Epoch 92 [4800/8000 (60%)]\tTraining loss: 0.0029 \tTraining accuracy: 100.0%\n",
      "Epoch 92 [6400/8000 (80%)]\tTraining loss: 0.0042 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1638 \tAccuracy: 95.333%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 93 [0/8000 (0%)]\tTraining loss: 0.0039 \tTraining accuracy: 100.0%\n",
      "Epoch 93 [1600/8000 (20%)]\tTraining loss: 0.0861 \tTraining accuracy: 97.6%\n",
      "Epoch 93 [3200/8000 (40%)]\tTraining loss: 0.0140 \tTraining accuracy: 99.6%\n",
      "Epoch 93 [4800/8000 (60%)]\tTraining loss: 0.0079 \tTraining accuracy: 100.0%\n",
      "Epoch 93 [6400/8000 (80%)]\tTraining loss: 0.0058 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1743 \tAccuracy: 95.056%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 94 [0/8000 (0%)]\tTraining loss: 0.0091 \tTraining accuracy: 99.9%\n",
      "Epoch 94 [1600/8000 (20%)]\tTraining loss: 0.0055 \tTraining accuracy: 100.0%\n",
      "Epoch 94 [3200/8000 (40%)]\tTraining loss: 0.0030 \tTraining accuracy: 100.0%\n",
      "Epoch 94 [4800/8000 (60%)]\tTraining loss: 0.0033 \tTraining accuracy: 100.0%\n",
      "Epoch 94 [6400/8000 (80%)]\tTraining loss: 0.0029 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1700 \tAccuracy: 95.611%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 95 [0/8000 (0%)]\tTraining loss: 0.0023 \tTraining accuracy: 100.0%\n",
      "Epoch 95 [1600/8000 (20%)]\tTraining loss: 0.0017 \tTraining accuracy: 100.0%\n",
      "Epoch 95 [3200/8000 (40%)]\tTraining loss: 0.0017 \tTraining accuracy: 100.0%\n",
      "Epoch 95 [4800/8000 (60%)]\tTraining loss: 0.0017 \tTraining accuracy: 100.0%\n",
      "Epoch 95 [6400/8000 (80%)]\tTraining loss: 0.0014 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1632 \tAccuracy: 95.778%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 96 [0/8000 (0%)]\tTraining loss: 0.0024 \tTraining accuracy: 100.0%\n",
      "Epoch 96 [1600/8000 (20%)]\tTraining loss: 0.0028 \tTraining accuracy: 100.0%\n",
      "Epoch 96 [3200/8000 (40%)]\tTraining loss: 0.0011 \tTraining accuracy: 100.0%\n",
      "Epoch 96 [4800/8000 (60%)]\tTraining loss: 0.0496 \tTraining accuracy: 98.5%\n",
      "Epoch 96 [6400/8000 (80%)]\tTraining loss: 0.0143 \tTraining accuracy: 99.9%\n",
      "\n",
      "Test set: Average loss: 0.1973 \tAccuracy: 94.778%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023060#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122200 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 97 [0/8000 (0%)]\tTraining loss: 0.0137 \tTraining accuracy: 99.9%\n",
      "Epoch 97 [1600/8000 (20%)]\tTraining loss: 0.0066 \tTraining accuracy: 100.0%\n",
      "Epoch 97 [3200/8000 (40%)]\tTraining loss: 0.0091 \tTraining accuracy: 99.9%\n",
      "Epoch 97 [4800/8000 (60%)]\tTraining loss: 0.0058 \tTraining accuracy: 99.9%\n",
      "Epoch 97 [6400/8000 (80%)]\tTraining loss: 0.0087 \tTraining accuracy: 99.9%\n",
      "\n",
      "Test set: Average loss: 0.1701 \tAccuracy: 95.556%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195262#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 98 [0/8000 (0%)]\tTraining loss: 0.0050 \tTraining accuracy: 99.9%\n",
      "Epoch 98 [1600/8000 (20%)]\tTraining loss: 0.0028 \tTraining accuracy: 100.0%\n",
      "Epoch 98 [3200/8000 (40%)]\tTraining loss: 0.0025 \tTraining accuracy: 100.0%\n",
      "Epoch 98 [4800/8000 (60%)]\tTraining loss: 0.0054 \tTraining accuracy: 99.9%\n",
      "Epoch 98 [6400/8000 (80%)]\tTraining loss: 0.0072 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1749 \tAccuracy: 95.389%\n",
      "\n",
      "Examples: prediction | input\n",
      "4440689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023063#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 99 [0/8000 (0%)]\tTraining loss: 0.0327 \tTraining accuracy: 98.8%\n",
      "Epoch 99 [1600/8000 (20%)]\tTraining loss: 0.0128 \tTraining accuracy: 99.7%\n",
      "Epoch 99 [3200/8000 (40%)]\tTraining loss: 0.0058 \tTraining accuracy: 99.9%\n",
      "Epoch 99 [4800/8000 (60%)]\tTraining loss: 0.0053 \tTraining accuracy: 100.0%\n",
      "Epoch 99 [6400/8000 (80%)]\tTraining loss: 0.0043 \tTraining accuracy: 100.0%\n",
      "\n",
      "Test set: Average loss: 0.1587 \tAccuracy: 95.944%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023062#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195262#0 \t six one nine five two six six\n",
      "\n",
      "Epoch 100 [0/8000 (0%)]\tTraining loss: 0.0038 \tTraining accuracy: 100.0%\n",
      "Epoch 100 [1600/8000 (20%)]\tTraining loss: 0.0043 \tTraining accuracy: 100.0%\n",
      "Epoch 100 [3200/8000 (40%)]\tTraining loss: 0.0027 \tTraining accuracy: 100.0%\n",
      "Epoch 100 [4800/8000 (60%)]\tTraining loss: 0.0029 \tTraining accuracy: 100.0%\n",
      "Epoch 100 [6400/8000 (80%)]\tTraining loss: 0.0194 \tTraining accuracy: 99.2%\n",
      "\n",
      "Test set: Average loss: 0.2113 \tAccuracy: 94.611%\n",
      "\n",
      "Examples: prediction | input\n",
      "4740689#0 \t four seven four zero six eight nine\n",
      "631498#00 \t six three one four nine eight\n",
      "59276#000 \t five nine two seven six\n",
      "091090#00 \t zero nine one zero nine zero\n",
      "023061#00 \t zero two three zero six three\n",
      "61319#000 \t six one three one nine\n",
      "43680#000 \t four three six eight zero\n",
      "292554#00 \t two nine two five five four\n",
      "558122#00 \t five five eight one two two\n",
      "6195266#0 \t six one nine five two six six\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(NUM_INPUTS, NUM_UNITS_ENC).to(device)\n",
    "decoder = DecoderRNN(NUM_UNITS_DEC, NUM_OUTPUTS).to(device)\n",
    "enc_optimizer = optim.RMSprop(encoder.parameters(), lr=LEARNING_RATE)\n",
    "dec_optimizer = optim.RMSprop(decoder.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get training set\n",
    "inputs, _, targets_in, targets, targets_seqlen, _, _, _, text_targ = generate(TRAINING_SIZE, min_len=MIN_SEQ_LEN, max_len=MAX_SEQ_LEN)\n",
    "max_target_len = max(targets_seqlen)\n",
    "inputs = torch.tensor(inputs)\n",
    "targets = torch.tensor(targets)\n",
    "targets_in = torch.tensor(targets_in)\n",
    "unique_text_targets = set(text_targ)\n",
    "\n",
    "# Get validation set\n",
    "val_inputs, _, val_targets_in, val_targets, val_targets_seqlen, _, val_text_in, _, val_text_targ = \\\n",
    "    generate(TEST_SIZE, min_len=MIN_SEQ_LEN, max_len=MAX_SEQ_LEN, invalid_set=unique_text_targets)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "val_targets = torch.tensor(val_targets)\n",
    "val_targets_in = torch.tensor(val_targets_in)\n",
    "max_val_target_len = max(val_targets_seqlen)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split training set in batches\n",
    "\n",
    "inputs =[inputs[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "targets = [targets[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "targets_in = [targets_in[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "\n",
    "\n",
    "\n",
    "# Quick and dirty - just loop over training set without reshuffling\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(encoder, decoder, inputs, targets, targets_in, criterion, enc_optimizer, dec_optimizer, epoch, max_target_len)\n",
    "    _, loss, accuracy = test(encoder, decoder, val_inputs, val_targets, val_targets_in, criterion, max_val_target_len)\n",
    "    print('\\nTest set: Average loss: {:.4f} \\tAccuracy: {:.3f}%\\n'.format(loss, accuracy.item()*100.))\n",
    "\n",
    "    # Show examples\n",
    "    print(\"Examples: prediction | input\")\n",
    "    out, _, _ = test(encoder, decoder, val_inputs[:10], val_targets[:10], val_targets_in[:10], criterion, max_val_target_len)\n",
    "    pred = get_pred(out)\n",
    "    pred_text = [numbers_to_text(sample) for sample in pred]\n",
    "    for i in range(10):\n",
    "        print(pred_text[i], \"\\t\", val_text_in[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "\n",
    "1. Implement missing code for the network in the *train* function. Your validation accuracy is expected to be <20% at this point.\n",
    "2. These networks implement the GRU-gates. Implement an alternative control utilising a memory mechanism (Hint: LSTM). What do you experience? \n",
    "3. There are some parameters in the model that may be optimized further, what could they be? Achieve >90% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment answers\n",
    "\n",
    "With the \"vanilla\" network I reached arround $55\\%$ accuracy. Then, I change the GRU-gates with LSTM ones and got over $75\\%$ accuracy. After that, some parameters could still be optimized further like batch size, number of hidden unit in encoder and decoder, learning rates, number of epochs and teacher forcing. \n",
    "\n",
    "I first, switch `TEACHER_FORCING` to **True**, and it was a big improvment, I reached an accuracy of $83\\%$. But I had to add a few epochs to get a full view on the performances at this point.  \n",
    "\n",
    "Finally, a tweaked a bit further some parameters, like batch size and number of hidden units and I manage to get an accuracy of $94.6\\%$ after 100 epochs, which seems quite good. However I should have stop the learning earlier because the network was not really imporving after epoch 41. However the accuracy peak was reached at epoch 89 (with $96.3\\%$ accuracy). \n",
    "\n",
    "Final values of the parameters (and answer to question 3):\n",
    "\n",
    "* `BATCH_SIZE = 80`\n",
    "* `NUM_UNITS_ENC = NUM_UNITS_DEC = 96`\n",
    "* `TEACHER_FORCING = True`\n",
    "* `NUM_EPOCH = 100`\n",
    "* `LEARNING_RATE = 0.003`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise from Michael Nielsen's book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to prove that the standard deviation of $z=\\sum_j w_jx_j + b$ is $\\sqrt{3/2}$ if the weights are randomly initialized from a distribution that has a standard deviation of $\\frac{1}{\\sqrt{n_{in}}}$ where $n_{in}$ is the number of input weights. Bias should still be initialized from a distribution with a standard deviation of $1$ though. \n",
    "\n",
    "First we compute the variance of $z$.\n",
    "\n",
    "$$ V(z) = V(\\sum_j w_jx_j + b) = \\sum_j V(w_j)x_j + V(b) $$\n",
    "\n",
    "The last equality comes from the fact that the $w_j$ and the bias are independant random variables and in such circumstances, the variance is linear. \n",
    "\n",
    "We did not mention it before but the standard deviation of $z$ should be computed for $n_{in}=1000$ and we have to consider that half of the $x_j$ are $0$ while the other half is $1$.\n",
    "\n",
    "Then we got:\n",
    "\n",
    "$$V(z) = \\sum_{j=1}^{500}V(w_j) + V(b) = 500.\\frac{1}{1000} + 1 =\\frac{3}{2}$$\n",
    "\n",
    "Finally, $$\\sigma(z) = \\sqrt{V(z)} = \\sqrt{3/2}$$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
